{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data/train.csv').set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "0000997932d777bf    Explanation\\nWhy the edits made under my usern...\n",
       "000103f0d9cfb60f    D'aww! He matches this background colour I'm s...\n",
       "000113f07ec002fd    Hey man, I'm really not trying to edit war. It...\n",
       "0001b41b1c6bb37e    \"\\nMore\\nI can't make any real suggestions on ...\n",
       "0001d958c54c6e35    You, sir, are my hero. Any chance you remember...\n",
       "Name: comment_text, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = dataset.comment_text\n",
    "documents.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## new bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127656,)\n",
      "(31915,)\n",
      "(127656, 6)\n",
      "(31915, 6)\n"
     ]
    }
   ],
   "source": [
    "original_columns = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "X, y = dataset.comment_text, dataset[original_columns]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "for s in X_train, X_test, y_train, y_test:\n",
    "    print(s.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['toxic']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_columns = original_columns[:1]\n",
    "our_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ad-hoc begins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = our_columns[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.3 s, sys: 404 ms, total: 22.7 s\n",
      "Wall time: 22.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vectorizer = CountVectorizer(\n",
    "    analyzer=\"word\", stop_words='english', ngram_range=(1, 2), max_features=100000)\n",
    "vect_train = vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### peek at most common tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article                46321\n",
       "wikipedia              38945\n",
       "page                   37060\n",
       "talk                   29794\n",
       "like                   22456\n",
       "just                   22316\n",
       "don                    18924\n",
       "think                  16047\n",
       "know                   15195\n",
       "people                 14870\n",
       "edit                   14639\n",
       "articles               13532\n",
       "use                    13361\n",
       "time                   12787\n",
       "did                    11929\n",
       "user                   11325\n",
       "thanks                 11135\n",
       "talk page              10784\n",
       "make                   10523\n",
       "good                   10321\n",
       "ve                      9834\n",
       "information             9736\n",
       "does                    9708\n",
       "want                    9301\n",
       "deletion                9166\n",
       "way                     9091\n",
       "sources                 9011\n",
       "image                   8830\n",
       "wp                      8735\n",
       "pages                   8605\n",
       "                       ...  \n",
       "probly                     5\n",
       "subject topic              5\n",
       "subject edit               5\n",
       "subject covered            5\n",
       "style solid                5\n",
       "subject copyright          5\n",
       "style talk                 5\n",
       "style use                  5\n",
       "style want                 5\n",
       "stylistically              5\n",
       "iczn                       5\n",
       "styrofoam                  5\n",
       "sub genres                 5\n",
       "sub group                  5\n",
       "process making             5\n",
       "sub topics                 5\n",
       "subalpine                  5\n",
       "subalpine fir              5\n",
       "process long               5\n",
       "subcommittee               5\n",
       "idea book                  5\n",
       "subcutaneous fibers        5\n",
       "process known              5\n",
       "subgroups                  5\n",
       "subject add                5\n",
       "subject ask                5\n",
       "process image              5\n",
       "subject certain            5\n",
       "process fact               5\n",
       "musician ensemble          5\n",
       "Name: 0, Length: 100000, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(vect_train.sum(axis=0).T, index=vectorizer.get_feature_names())\\\n",
    "    [0].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127656, 100000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "# from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.24 s, sys: 4 ms, total: 6.25 s\n",
      "Wall time: 6.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "classifier = LinearSVC()\n",
    "classifier.fit(vect_train, y_train[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.952968823437\n",
      "CPU times: user 2.64 s, sys: 0 ns, total: 2.64 s\n",
      "Wall time: 2.64 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vect_test = vectorizer.transform(X_test)\n",
    "y_pred = pd.Series(classifier.predict(vect_test), y_test.index)\n",
    "score = classifier.score(vect_test, y_test[col])\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### log losses: simple, cutoff 4%, cutoff from score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.62441580146\n",
      "0.190289605341\n",
      "0.189679152518\n"
     ]
    }
   ],
   "source": [
    "ll_simple = log_loss(y_test[col], y_pred)\n",
    "print(ll_simple)\n",
    "\n",
    "cutoff = 0.04\n",
    "y_pred_cut004 = y_pred.apply(lambda x: min(1 - cutoff, max(cutoff, x)))\n",
    "ll_cut004 = log_loss(y_test[col], y_pred_cut004)\n",
    "print(ll_cut004)\n",
    "\n",
    "cutoff = 1 - score\n",
    "y_pred_score_cut = y_pred.apply(lambda x: min(1 - cutoff, max(cutoff, x)))\n",
    "ll_score_cut = log_loss(y_test[col], y_pred_score_cut)\n",
    "print(ll_score_cut)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:toxic]",
   "language": "python",
   "name": "conda-env-toxic-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
